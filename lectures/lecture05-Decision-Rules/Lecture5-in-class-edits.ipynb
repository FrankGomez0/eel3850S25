{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 5\n",
    "- Optimal Decisions for Discrete Stochastic Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Decisions for Discrete Stochastic Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handwritten Example: Binary Communication System**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('figures/bcs.png',width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "P = np.array([\n",
    "    [7/8, 1/8],\n",
    "    [1/6, 5/6]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.sum( P, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.sum(P, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Problem and Decision Rules\n",
    " Let $\\widehat{A}_i$ denote the event that the receiver decides that input was $A_i$. Then the ML decision rule given $B_j$ is observed is \n",
    "\n",
    "$$\n",
    "\\widehat{A}_i, \\mbox{ where } i = \\arg \\max_{i \\in \\{0,1\\}} P(B_j|A_i).\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "The values of $P(B_j|A_i)$ are given in the figure.  For each output, the ML rule selects the input that has the largest likelihood, which corresponds to the arrow with the largest probability merging into that output in the figure. Similarly, the ML decision corresponds to the row number with the largest probability for each column of the transition probability matrix, $\\mathbf{P}$. To get the index of the largest value in each column, we can use the `np.argmax()` function and pass the `axis=0` keyword parameter to tell NumPy to maximize over the rows. (Note that `np.max()` returns the maximum value, whereas `np.argmax()` returns the index of the maximum value.)\n",
    "\n",
    "Thus, the ML decisions are as follows:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.argmax(P, axis=0) # calculate the maximal i that generates the j-th observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read these decisions as follows. The value in position $j$ is the decision given $B_j$ is received. Then the decision rules are as follows:\n",
    "* Given $B_0$ is received, decide $A_0$.\n",
    "* Given $B_1$ is received, decide $A_1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose $P(A_0) =1$: \n",
    "\n",
    "Let $E$ be the event that an error occurs (i.e., the decision differs from the transmitted symbol). Then for this simple example, $P(E) =  P(B_1|A_0) = 0.125$. We know that it is suboptimal because we could just use the decision rule \"Always decide $A_0$\" and get error probability 0.\n",
    "\n",
    "We can guess that there must be some value $q_0$ such that:\n",
    "* if $P(A_0)<q_0$, the ML rule performs better, and\n",
    "* if $P(A_0)>q_0$, always deciding $A_0$ performs better.\n",
    "\n",
    "Let's build a simulation to test this. First, we will see how to efficiently generate the events $A_0$ and $A_1$ given any probabilities $P(A_0)$ and $P(A_1)$ such that $P(A_0)+P(A_1) = 1$. We will again use NumPy's `npr.choice()` function and pass on the probability as addtional variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, if we want to output a 0 with probability $P(A_0)=0.75$ and a 1 with probability $P(A_1)=0.25$, we can simulate 1000 such events as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we are ready to build a function to carry out the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sim2to2 (decision_rule, P, PA0, num_sims = 10_000, verbose = False):\n",
    "    # Create all the input events at the same time:\n",
    "    inputs = npr.choice([0, 1], num_sims, p = [PA0, 1-PA0])\n",
    "    \n",
    "    # Create an array to determine the channel outputs\n",
    "     \n",
    "    # Create an array to store the decisions\n",
    "     \n",
    "    # There are more efficient ways of doing this using NumPy, but\n",
    "    # individually determining each output for each input should make \n",
    "    # this easier to understand for most learners\n",
    "    for sim in range(num_sims):\n",
    "        # Choose observation according to transition probabilities for given input bit:\n",
    "         # Now pass this observation to the decision_rule function: \n",
    "    \n",
    "    # Finally, calculate the error probability. An error occurs\n",
    "    # whenever the decision is not equal to the true input\n",
    "    errors = np.sum(inputs!=decisions)\n",
    "    error_prob = errors/num_sims\n",
    "    if verbose:\n",
    "        print( f'The error probability is approximately {error_prob:.2f}')\n",
    "    return error_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def always_decide0(observation, P, PA0):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def MLE (observation, P, PA0):\n",
    "    return np.argmax(P[:, observation]) # select the column corresponding to P(B_j|A_i), i=0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s create one more decision rule function: always decide A1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code calculates the error probabilities for these three decision rules as\n",
    "a function of $P(A_0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm # show progress in computation\n",
    "\n",
    "input_probs = np.linspace(0,1,21) # calculate 21 discrete points from 0,1, approximate the continuous probability value\n",
    "\n",
    "pe_always0 = []\n",
    "pe_always1 = []\n",
    "pe_ML = []\n",
    "\n",
    "for PA0 in tqdm(input_probs): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('$P(A_0)$')\n",
    "plt.ylabel('Error probability');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Rules- MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "  <strong>Maximum A Posteriori (MAP) Decision Rule</strong>\n",
    "\n",
    "If the set of events $\\{A_0, A_1\\}$ partitions $\\Omega$, and assuming $P(A_i)>0$, for all $i$. Then the Maximum A Posteriori decision rule is given by:\n",
    "    \n",
    "\\begin{align*}\n",
    "P(A_0|B) &\\underset{A_1}{\\overset{A_0}{\\gtrless}} P(A_1|B) \\\\\n",
    "\\iff \\frac{P(B|A_0)P(A_0)}{P(B)} &\\underset{A_1}{\\overset{A_0}{\\gtrless}} \\frac{P(B|A_1)P(A_1)}{P(B)}\n",
    "\\end{align*}\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The APPs can be computed by implementing Bayes’ rule in Python as follows for\n",
    "$P(A_0) = 2/5$ and $P(A_1) = 3/5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aprioris = np.array([2/5,3/5])\n",
    "for j in range(2):\n",
    "    pBj = 0\n",
    "    for i in range(2):\n",
    "        # complete the calculation of P(B_j)\n",
    "        print(f'P(B{j}) = {pBj:.2f}: ', end = '')\n",
    "\n",
    "    for i in range(2):\n",
    "        # Complete the calculation of P(A_i|B_j)\n",
    "        print(f'P(A{i}|B{j})={ : .2f}',end=' ')       \n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It chooses $A_0$ if observing $B_0$, and choose $A_1$ if observing $B_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these example a prioris, we see that the MAP rule is not any of the three rules\n",
    "previously introduced! Let’s create a MAP decision rule function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def MAP(observation, P, PA0):\n",
    "    # Take the jth column and multiply it elementwise by the\n",
    "    # a priori probability vector\n",
    "    return np.argmax(scaled_apps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code simulates the performance of all of the decision rules discussed for\n",
    "different values of the a priori probability P(A0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_probs = np.linspace(0,1,21)\n",
    "\n",
    "pe_always0 = []\n",
    "pe_always1 = []\n",
    "pe_ML = []\n",
    "pe_MAP = []\n",
    "\n",
    "for PA0 in tqdm(input_probs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('$P(A_0)$')\n",
    "plt.ylabel('Error probability');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the MAP rule achieves the lowest error probability for all values of\n",
    "$P(A_0)$. However, this requires the receiver to know the a priori values of the inputs. If the\n",
    "a priori probabilities are not known, then the ML decision rule is usually used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
